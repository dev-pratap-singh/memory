{
  "models": {
    "gpt-4": {
      "context_length": 8192,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 4096,
      "cost_per_1k_input": 0.03,
      "cost_per_1k_output": 0.06
    },
    "gpt-4-32k": {
      "context_length": 32768,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 8192,
      "cost_per_1k_input": 0.06,
      "cost_per_1k_output": 0.12
    },
    "gpt-4-turbo": {
      "context_length": 128000,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 4096,
      "cost_per_1k_input": 0.01,
      "cost_per_1k_output": 0.03
    },
    "gpt-4o": {
      "context_length": 128000,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 16384,
      "cost_per_1k_input": 0.0025,
      "cost_per_1k_output": 0.01
    },
    "gpt-4o-mini": {
      "context_length": 128000,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 16384,
      "cost_per_1k_input": 0.00015,
      "cost_per_1k_output": 0.0006
    },
    "gpt-3.5-turbo": {
      "context_length": 16385,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 4096,
      "cost_per_1k_input": 0.0005,
      "cost_per_1k_output": 0.0015
    },
    "gpt-3.5-turbo-16k": {
      "context_length": 16385,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 4096,
      "cost_per_1k_input": 0.001,
      "cost_per_1k_output": 0.002
    },
    "gpt-5": {
      "context_length": 200000,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 16384,
      "cost_per_1k_input": 0.005,
      "cost_per_1k_output": 0.015
    },
    "claude-3-opus": {
      "context_length": 200000,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 4096,
      "cost_per_1k_input": 0.015,
      "cost_per_1k_output": 0.075
    },
    "claude-3-sonnet": {
      "context_length": 200000,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 4096,
      "cost_per_1k_input": 0.003,
      "cost_per_1k_output": 0.015
    },
    "claude-3-haiku": {
      "context_length": 200000,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 4096,
      "cost_per_1k_input": 0.00025,
      "cost_per_1k_output": 0.00125
    },
    "gemma-3-4b": {
      "context_length": 8192,
      "safe_threshold": 0.85,
      "compression_trigger": 0.75,
      "max_tokens": 2048,
      "cost_per_1k_input": 0.0,
      "cost_per_1k_output": 0.0
    }
  },
  "compression_strategies": {
    "aggressive": {
      "summary_ratio": 0.1,
      "detail_retention": "minimal"
    },
    "balanced": {
      "summary_ratio": 0.25,
      "detail_retention": "moderate"
    },
    "conservative": {
      "summary_ratio": 0.5,
      "detail_retention": "high"
    }
  },
  "memory_management": {
    "max_compressed_items": 50,
    "auto_prune_after_days": 30,
    "context_quarantine_enabled": true,
    "chat_hygiene_interval": 10
  }
}
