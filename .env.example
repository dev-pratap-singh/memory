# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=memory_db
DB_USER=postgres
DB_PASSWORD=your_secure_password_here

# API Keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Application Settings
ENVIRONMENT=development  # development, staging, production
DEBUG=true
LOG_LEVEL=INFO

# Model Settings
USE_GPU=true
CUDA_VISIBLE_DEVICES=0
TRANSFORMERS_CACHE=/app/models/cache

# Security
SECRET_KEY=your-secret-key-here-change-in-production
API_KEY=your-api-key-here

# Redis (for task queue)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=9090

# Memory Management Configuration
# MEMORY_APPROACH: Choose between 'external_llm' (Approach 1) or 'slm' (Approach 2)
# - external_llm: Context partitioning with compression/summarization for external LLMs
# - slm: Dual-model system with Small Language Model for memory management
MEMORY_APPROACH=external_llm

# Primary LLM Configuration (used for reasoning and responses)
PRIMARY_LLM_PROVIDER=openai  # openai, anthropic
PRIMARY_LLM_MODEL=gpt-4o-mini  # gpt-4o, gpt-4o-mini, gpt-4-turbo, claude-3-sonnet, etc.

# SLM Configuration (optional, used when MEMORY_APPROACH=slm)
USE_SLM=false  # Enable/disable Small Language Model for memory management
SLM_MODEL_NAME=microsoft/phi-2  # gemma-3-4b, microsoft/phi-2, etc.
USE_LORA_FINETUNING=false  # Enable/disable LoRA fine-tuning for SLM

# Feature Flags
ENABLE_AUTO_TRAINING=true
ENABLE_COMPRESSION=true
ENABLE_SUMMARIZATION=true
